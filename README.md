<!---
WARNING: DO NOT EDIT THIS FILE DIRECTLY. IT IS GENERATED BY src/pull_available_models.py
--->
# Free LLM API resources

This lists various services that provide free access or credits towards API-based LLM usage.

> [!NOTE]  
> Please don't abuse these services, else we might lose them.

> [!WARNING]  
> This list explicitly excludes any services that are not legitimate (eg reverse engineers an existing chatbot)

- [Free Providers](#free-providers)
  - [OpenRouter](#openrouter)
  - [Google AI Studio](#google-ai-studio)
  - [NVIDIA NIM](#nvidia-nim)
  - [Mistral (La Plateforme)](#mistral-la-plateforme)
  - [Mistral (Codestral)](#mistral-codestral)
  - [HuggingFace Inference Providers](#huggingface-inference-providers)
  - [Cerebras](#cerebras)
  - [Groq](#groq)
  - [OVH AI Endpoints (Free Beta)](#ovh-ai-endpoints-free-beta)
  - [Together (Free)](#together-free)
  - [Cohere](#cohere)
  - [GitHub Models](#github-models)
  - [Chutes](#chutes)
  - [Cloudflare Workers AI](#cloudflare-workers-ai)
  - [Google Cloud Vertex AI](#google-cloud-vertex-ai)
- [Providers with trial credits](#providers-with-trial-credits)
  - [Together](#together)
  - [Fireworks](#fireworks)
  - [Unify](#unify)
  - [Baseten](#baseten)
  - [Nebius](#nebius)
  - [Novita](#novita)
  - [AI21](#ai21)
  - [Upstage](#upstage)
  - [NLP Cloud](#nlp-cloud)
  - [Alibaba Cloud (International) Model Studio](#alibaba-cloud-international-model-studio)
  - [Modal](#modal)
  - [Hyperbolic](#hyperbolic)
  - [SambaNova Cloud](#sambanova-cloud)
  - [Scaleway Generative APIs](#scaleway-generative-apis)

## Free Providers

### [OpenRouter](https://openrouter.ai)

**Limits:**

[20 requests/minute<br>50 requests/day<br>1000 requests/day with $10 credit balance](https://openrouter.ai/docs/api-reference/limits)

Models share a common quota.

- [Bytedance UI Tars 72B](https://openrouter.ai/bytedance-research/ui-tars-72b:free)
- [DeepCoder 14B Preview](https://openrouter.ai/agentica-org/deepcoder-14b-preview:free)
- [DeepHermes 3 Llama 3 8B Preview](https://openrouter.ai/nousresearch/deephermes-3-llama-3-8b-preview:free)
- [DeepSeek R1](https://openrouter.ai/deepseek/deepseek-r1:free)
- [DeepSeek R1 Distill Llama 70B](https://openrouter.ai/deepseek/deepseek-r1-distill-llama-70b:free)
- [DeepSeek R1 Distill Qwen 14B](https://openrouter.ai/deepseek/deepseek-r1-distill-qwen-14b:free)
- [DeepSeek R1 Distill Qwen 32B](https://openrouter.ai/deepseek/deepseek-r1-distill-qwen-32b:free)
- [DeepSeek R1 Zero](https://openrouter.ai/deepseek/deepseek-r1-zero:free)
- [DeepSeek V3](https://openrouter.ai/deepseek/deepseek-chat:free)
- [DeepSeek V3 0324](https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free)
- [DeepSeek V3 Base](https://openrouter.ai/deepseek/deepseek-v3-base:free)
- [Dolphin 3.0 Mistral 24B](https://openrouter.ai/cognitivecomputations/dolphin3.0-mistral-24b:free)
- [Dolphin 3.0 R1 Mistral 24B](https://openrouter.ai/cognitivecomputations/dolphin3.0-r1-mistral-24b:free)
- [Featherless Qwerky 72B](https://openrouter.ai/featherless/qwerky-72b:free)
- [Gemini 2.5 Pro Experimental 03-25](https://openrouter.ai/google/gemini-2.5-pro-exp-03-25:free)
- [Gemma 2 9B Instruct](https://openrouter.ai/google/gemma-2-9b-it:free)
- [Gemma 3 12B Instruct](https://openrouter.ai/google/gemma-3-12b-it:free)
- [Gemma 3 1B Instruct](https://openrouter.ai/google/gemma-3-1b-it:free)
- [Gemma 3 27B Instruct](https://openrouter.ai/google/gemma-3-27b-it:free)
- [Gemma 3 4B Instruct](https://openrouter.ai/google/gemma-3-4b-it:free)
- [Kimi VL A3B Thinking](https://openrouter.ai/moonshotai/kimi-vl-a3b-thinking:free)
- [Llama 3.1 8B Instruct](https://openrouter.ai/meta-llama/llama-3.1-8b-instruct:free)
- [Llama 3.1 Nemotron 70B Instruct](https://openrouter.ai/nvidia/llama-3.1-nemotron-70b-instruct:free)
- [Llama 3.1 Nemotron Nano 8B v1](https://openrouter.ai/nvidia/llama-3.1-nemotron-nano-8b-v1:free)
- [Llama 3.1 Nemotron Ultra 253B v1](https://openrouter.ai/nvidia/llama-3.1-nemotron-ultra-253b-v1:free)
- [Llama 3.2 11B Vision Instruct](https://openrouter.ai/meta-llama/llama-3.2-11b-vision-instruct:free)
- [Llama 3.2 1B Instruct](https://openrouter.ai/meta-llama/llama-3.2-1b-instruct:free)
- [Llama 3.2 3B Instruct](https://openrouter.ai/meta-llama/llama-3.2-3b-instruct:free)
- [Llama 3.3 70B Instruct](https://openrouter.ai/meta-llama/llama-3.3-70b-instruct:free)
- [Llama 3.3 Nemotron Super 49B v1](https://openrouter.ai/nvidia/llama-3.3-nemotron-super-49b-v1:free)
- [Llama 4 Maverick](https://openrouter.ai/meta-llama/llama-4-maverick:free)
- [Llama 4 Scout](https://openrouter.ai/meta-llama/llama-4-scout:free)
- [Mistral 7B Instruct](https://openrouter.ai/mistralai/mistral-7b-instruct:free)
- [Mistral Nemo](https://openrouter.ai/mistralai/mistral-nemo:free)
- [Mistral Small 24B Instruct 2501](https://openrouter.ai/mistralai/mistral-small-24b-instruct-2501:free)
- [Mistral Small 3.1 24B Instruct](https://openrouter.ai/mistralai/mistral-small-3.1-24b-instruct:free)
- [Molmo 7B D](https://openrouter.ai/allenai/molmo-7b-d:free)
- [Moonlight-16B-A3B-Instruct](https://openrouter.ai/moonshotai/moonlight-16b-a3b-instruct:free)
- [OlympicCoder 32B](https://openrouter.ai/open-r1/olympiccoder-32b:free)
- [OlympicCoder 7B](https://openrouter.ai/open-r1/olympiccoder-7b:free)
- [QwQ 32B ArliAI RpR v1](https://openrouter.ai/arliai/qwq-32b-arliai-rpr-v1:free)
- [Qwen 2.5 72B Instruct](https://openrouter.ai/qwen/qwen-2.5-72b-instruct:free)
- [Qwen 2.5 7B Instruct](https://openrouter.ai/qwen/qwen-2.5-7b-instruct:free)
- [Qwen 2.5 VL 32B Instruct](https://openrouter.ai/qwen/qwen2.5-vl-32b-instruct:free)
- [Qwen 2.5 VL 3B Instruct](https://openrouter.ai/qwen/qwen2.5-vl-3b-instruct:free)
- [Qwen 2.5 VL 7B Instruct](https://openrouter.ai/qwen/qwen-2.5-vl-7b-instruct:free)
- [Qwen QwQ 32B](https://openrouter.ai/qwen/qwq-32b:free)
- [Qwen QwQ 32B Preview](https://openrouter.ai/qwen/qwq-32b-preview:free)
- [Qwen2.5 Coder 32B Instruct](https://openrouter.ai/qwen/qwen-2.5-coder-32b-instruct:free)
- [Qwen2.5 VL 72B Instruct](https://openrouter.ai/qwen/qwen2.5-vl-72b-instruct:free)
- [Reka Flash 3](https://openrouter.ai/rekaai/reka-flash-3:free)
- [Rogue Rose 103B v0.2](https://openrouter.ai/sophosympatheia/rogue-rose-103b-v0.2:free)
- [Shisa V2 Llama 3.3 70B](https://openrouter.ai/shisa-ai/shisa-v2-llama3.3-70b:free)
- [Zephyr 7B Beta](https://openrouter.ai/huggingfaceh4/zephyr-7b-beta:free)
- [thudm/glm-4-32b:free](https://openrouter.ai/thudm/glm-4-32b:free)
- [thudm/glm-z1-32b:free](https://openrouter.ai/thudm/glm-z1-32b:free)

### [Google AI Studio](https://aistudio.google.com)

Data is used for training when used outside of the UK/CH/EEA/EU.

<table><thead><tr><th>Model Name</th><th>Model Limits</th></tr></thead><tbody>
<tr><td>Gemini 2.5 Pro (Experimental)</td><td>1,000,000 tokens/day<br>250,000 tokens/minute<br>25 requests/day<br>5 requests/minute</td></tr>
<tr><td>Gemini 2.5 Flash (Preview)</td><td>250,000 tokens/minute<br>500 requests/day<br>10 requests/minute</td></tr>
<tr><td>Gemini 2.0 Flash</td><td>1,000,000 tokens/minute<br>1,500 requests/day<br>15 requests/minute</td></tr>
<tr><td>Gemini 2.0 Flash-Lite</td><td>1,000,000 tokens/minute<br>1,500 requests/day<br>30 requests/minute</td></tr>
<tr><td>Gemini 2.0 Flash (Experimental)</td><td>4,000,000 tokens/minute<br>1,500 requests/day<br>10 requests/minute</td></tr>
<tr><td>Gemini 1.5 Flash</td><td>1,000,000 tokens/minute<br>1,500 requests/day<br>15 requests/minute</td></tr>
<tr><td>Gemini 1.5 Flash-8B</td><td>1,000,000 tokens/minute<br>1,500 requests/day<br>15 requests/minute</td></tr>
<tr><td>Gemini 1.5 Pro</td><td>32,000 tokens/minute<br>50 requests/day<br>2 requests/minute</td></tr>
<tr><td>LearnLM 1.5 Pro (Experimental)</td><td>1,500 requests/day<br>15 requests/minute</td></tr>
<tr><td>Gemma 3 27B Instruct</td><td>15,000 tokens/minute<br>14,400 requests/day<br>30 requests/minute</td></tr>
<tr><td>Gemma 3 12B Instruct</td><td>15,000 tokens/minute<br>14,400 requests/day<br>30 requests/minute</td></tr>
<tr><td>Gemma 3 4B Instruct</td><td>15,000 tokens/minute<br>14,400 requests/day<br>30 requests/minute</td></tr>
<tr><td>Gemma 3 1B Instruct</td><td>15,000 tokens/minute<br>14,400 requests/day<br>30 requests/minute</td></tr>
<tr><td>text-embedding-004</td><td rowspan="2">150 batch requests/minute<br>1,500 requests/minute<br>100 content/batch<br>Shared Quota</td></tr>
<tr><td>embedding-001</td></tr>
</tbody></table>

### [NVIDIA NIM](https://build.nvidia.com/explore/discover)

Phone number verification required.
Models tend to be context window limited.

**Limits:** 40 requests/minute

- [Various open models](https://build.nvidia.com/models)

### [Mistral (La Plateforme)](https://console.mistral.ai/)

* Free tier (Experiment plan) requires opting into data training
* Requires phone number verification.

**Limits (per-model):** 1 request/second, 500,000 tokens/minute, 1,000,000,000 tokens/month

- [Open and Proprietary Mistral models](https://docs.mistral.ai/getting-started/models/models_overview/)

### [Mistral (Codestral)](https://codestral.mistral.ai/)

* Currently free to use
* Monthly subscription based
* Requires phone number verification

**Limits:** 30 requests/minute, 2,000 requests/day

- Codestral

### [HuggingFace Inference Providers](https://huggingface.co/docs/inference-providers/en/index)

HuggingFace Serverless Inference limited to models smaller than 10GB. Some popular models are supported even if they exceed 10GB.

**Limits:** [$0.10/month in credits](https://huggingface.co/docs/inference-providers/en/pricing)

- Various open models across supported providers

### [Cerebras](https://cloud.cerebras.ai/)

Free tier restricted to 8K context.

<table><thead><tr><th>Model Name</th><th>Model Limits</th></tr></thead><tbody>
<tr><td>Llama 4 Scout</td><td>30 requests/minute<br>60,000 tokens/minute<br>900 requests/hour<br>1,000,000 tokens/hour<br>14,400 requests/day<br>1,000,000 tokens/day</td></tr>
<tr><td>Llama 3.1 8B</td><td>30 requests/minute<br>60,000 tokens/minute<br>900 requests/hour<br>1,000,000 tokens/hour<br>14,400 requests/day<br>1,000,000 tokens/day</td></tr>
<tr><td>Llama 3.3 70B</td><td>30 requests/minute<br>60,000 tokens/minute<br>900 requests/hour<br>1,000,000 tokens/hour<br>14,400 requests/day<br>1,000,000 tokens/day</td></tr>
</tbody></table>

### [Groq](https://console.groq.com)

<table><thead><tr><th>Model Name</th><th>Model Limits</th></tr></thead><tbody>
<tr><td>Allam 2 7B</td><td>7,000 requests/day<br>6,000 tokens/minute</td></tr>
<tr><td>DeepSeek R1 Distill Llama 70B</td><td>1,000 requests/day<br>6,000 tokens/minute</td></tr>
<tr><td>Distil Whisper Large v3</td><td>7,200 audio-seconds/minute<br>2,000 requests/day</td></tr>
<tr><td>Gemma 2 9B Instruct</td><td>14,400 requests/day<br>15,000 tokens/minute</td></tr>
<tr><td>Groq compound-beta</td><td>200 requests/day<br>70,000 tokens/minute</td></tr>
<tr><td>Groq compound-beta-mini</td><td>200 requests/day<br>70,000 tokens/minute</td></tr>
<tr><td>Llama 3 70B</td><td>14,400 requests/day<br>6,000 tokens/minute</td></tr>
<tr><td>Llama 3 8B</td><td>14,400 requests/day<br>6,000 tokens/minute</td></tr>
<tr><td>Llama 3.1 8B</td><td>14,400 requests/day<br>6,000 tokens/minute</td></tr>
<tr><td>Llama 3.3 70B</td><td>1,000 requests/day<br>12,000 tokens/minute</td></tr>
<tr><td>Llama 4 Maverick 17B 128E Instruct</td><td>1,000 requests/day<br>6,000 tokens/minute</td></tr>
<tr><td>Llama 4 Scout Instruct</td><td>1,000 requests/day<br>30,000 tokens/minute</td></tr>
<tr><td>Llama Guard 3 8B</td><td>14,400 requests/day<br>15,000 tokens/minute</td></tr>
<tr><td>Mistral Saba 24B</td><td>1,000 requests/day<br>6,000 tokens/minute</td></tr>
<tr><td>Qwen QwQ 32B</td><td>1,000 requests/day<br>6,000 tokens/minute</td></tr>
<tr><td>Whisper Large v3</td><td>7,200 audio-seconds/minute<br>2,000 requests/day</td></tr>
<tr><td>Whisper Large v3 Turbo</td><td>7,200 audio-seconds/minute<br>2,000 requests/day</td></tr>
</tbody></table>

### [OVH AI Endpoints (Free Beta)](https://endpoints.ai.cloud.ovh.net/)

<table><thead><tr><th>Model Name</th><th>Model Limits</th></tr></thead><tbody>
<tr><td>DeepSeek R1 Distill Llama 70B</td><td>12 requests/minute</td></tr>
<tr><td>Llama 3.1 70B Instruct</td><td>12 requests/minute</td></tr>
<tr><td>Llama 3.1 8B Instruct</td><td>12 requests/minute</td></tr>
<tr><td>Llama 3.3 70B Instruct</td><td>12 requests/minute</td></tr>
<tr><td>Llava Next Mistral 7B</td><td>12 requests/minute</td></tr>
<tr><td>Mamba Codestral 7B v0.1</td><td>12 requests/minute</td></tr>
<tr><td>Mistral 7B Instruct v0.3</td><td>12 requests/minute</td></tr>
<tr><td>Mistral Nemo 2407</td><td>12 requests/minute</td></tr>
<tr><td>Mixtral 8x7B Instruct v0.1</td><td>12 requests/minute</td></tr>
<tr><td>Qwen 2.5 VL 72B Instruct</td><td>12 requests/minute</td></tr>
<tr><td>Qwen2.5 Coder 32B Instruct</td><td>12 requests/minute</td></tr>
</tbody></table>

### [Together (Free)](https://together.ai)

**Limits:** Up to 60 requests/minute

- [Llama 3.2 11B Vision Instruct](https://together.ai/llama-3-2-11b-free)
- [Llama 3.3 70B Instruct](https://together.ai/llama-3-3-70b-free)
- [DeepSeek R1 Distil Llama 70B](https://together.ai/deepseek-r1-distilled-llama-70b-free)

### [Cohere](https://cohere.com)

**Limits:**

[20 requests/minute<br>1,000 requests/month](https://docs.cohere.com/docs/rate-limits)

Models share a common quota.

- Command-A
- Command-R7B
- Command-R+
- Command-R
- Aya Expanse 8B
- Aya Expanse 32B
- Aya Vision 8B
- Aya Vision 32B

### [GitHub Models](https://github.com/marketplace/models)

Extremely restrictive input/output token limits.

**Limits:** [Dependent on Copilot subscription tier (Free/Pro/Pro+/Business/Enterprise)](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits)

- AI21 Jamba 1.5 Large
- AI21 Jamba 1.5 Mini
- Codestral 25.01
- Cohere Command A
- Cohere Command R
- Cohere Command R 08-2024
- Cohere Command R+
- Cohere Command R+ 08-2024
- Cohere Embed 4
- Cohere Embed v3 English
- Cohere Embed v3 Multilingual
- DeepSeek-R1
- DeepSeek-V3-0324
- JAIS 30b Chat
- Llama 4 Maverick 17B 128E Instruct FP8
- Llama 4 Scout 17B 16E Instruct
- Llama-3.2-11B-Vision-Instruct
- Llama-3.2-90B-Vision-Instruct
- Llama-3.3-70B-Instruct
- MAI-DS-R1
- Meta-Llama-3-70B-Instruct
- Meta-Llama-3-8B-Instruct
- Meta-Llama-3.1-405B-Instruct
- Meta-Llama-3.1-70B-Instruct
- Meta-Llama-3.1-8B-Instruct
- Ministral 3B
- Mistral Large (2407)
- Mistral Large 24.11
- Mistral Nemo
- Mistral Small
- Mistral Small 3.1
- OpenAI GPT-4.1
- OpenAI GPT-4.1-mini
- OpenAI GPT-4.1-nano
- OpenAI GPT-4o
- OpenAI GPT-4o mini
- OpenAI Text Embedding 3 (large)
- OpenAI Text Embedding 3 (small)
- OpenAI o1
- OpenAI o1-mini
- OpenAI o1-preview
- OpenAI o3
- OpenAI o3-mini
- OpenAI o4-mini
- Phi-3-medium instruct (128k)
- Phi-3-medium instruct (4k)
- Phi-3-mini instruct (128k)
- Phi-3-mini instruct (4k)
- Phi-3-small instruct (128k)
- Phi-3-small instruct (8k)
- Phi-3.5-MoE instruct (128k)
- Phi-3.5-mini instruct (128k)
- Phi-3.5-vision instruct (128k)
- Phi-4
- Phi-4-mini-instruct
- Phi-4-multimodal-instruct

### [Chutes](https://chutes.ai/)

Distributed, decentralized crypto-based compute.
Data is sent to individual hosts.

- DeepCoder 14B Preview
- DeepHermes 3 Llama 3 8B Preview
- DeepSeek R1
- DeepSeek R1-Zero
- DeepSeek V3
- DeepSeek V3 0324
- DeepSeek V3 Base
- Dolphin 3.0 Mistral 24B
- Dolphin 3.0 R1 Mistral 24B
- Gemma 3 12B Instruct
- Gemma 3 1B Instruct
- Gemma 3 4B Instruct
- Kimi VL A3B Thinking
- Llama 3.1 Nemotron Nano 8B v1
- Llama 3.1 Nemotron Ultra 253B v1
- Llama 3.3 Nemotron Super 49B v1
- Llama 4 Maverick 17B 128E Instruct FP8
- Llama 4 Scout 17B 16E Instruct
- Mistral Small 3.1 24B Instruct 2503
- OlympicCoder 32B
- OlympicCoder 7B
- QwQ 32B ArliAI RpR v1
- Qwen 2.5 VL 32B Instruct
- Reka Flash 3
- Shisa V2 Llama 3.3 70B
- thudm/glm-4-32b-0414
- thudm/glm-z1-32b-0414

### [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai)

**Limits:** [10,000 neurons/day](https://developers.cloudflare.com/workers-ai/platform/pricing/#free-allocation)

- DeepSeek R1 Distill Qwen 32B
- Deepseek Coder 6.7B Base (AWQ)
- Deepseek Coder 6.7B Instruct (AWQ)
- Deepseek Math 7B Instruct
- Discolm German 7B v1 (AWQ)
- Falcom 7B Instruct
- Gemma 2B Instruct (LoRA)
- Gemma 3 12B Instruct
- Gemma 7B Instruct
- Gemma 7B Instruct (LoRA)
- Hermes 2 Pro Mistral 7B
- Llama 2 13B Chat (AWQ)
- Llama 2 7B Chat (FP16)
- Llama 2 7B Chat (INT8)
- Llama 2 7B Chat (LoRA)
- Llama 3 8B Instruct
- Llama 3 8B Instruct
- Llama 3 8B Instruct (AWQ)
- Llama 3.1 8B Instruct
- Llama 3.1 8B Instruct (AWQ)
- Llama 3.1 8B Instruct (FP8)
- Llama 3.2 11B Vision Instruct
- Llama 3.2 1B Instruct
- Llama 3.2 3B Instruct
- Llama 3.3 70B Instruct (FP8)
- Llama 4 Scout Instruct
- Llama Guard 3 8B
- LlamaGuard 7B (AWQ)
- Mistral 7B Instruct v0.1
- Mistral 7B Instruct v0.1 (AWQ)
- Mistral 7B Instruct v0.2
- Mistral 7B Instruct v0.2 (LoRA)
- Mistral Small 3.1 24B Instruct
- Neural Chat 7B v3.1 (AWQ)
- OpenChat 3.5 0106
- OpenHermes 2.5 Mistral 7B (AWQ)
- Phi-2
- Qwen 1.5 0.5B Chat
- Qwen 1.5 1.8B Chat
- Qwen 1.5 14B Chat (AWQ)
- Qwen 1.5 7B Chat (AWQ)
- Qwen 2.5 Coder 32B Instruct
- Qwen QwQ 32B
- SQLCoder 7B 2
- Starling LM 7B Beta
- TinyLlama 1.1B Chat v1.0
- Una Cybertron 7B v2 (BF16)
- Zephyr 7B Beta (AWQ)

### [Google Cloud Vertex AI](https://console.cloud.google.com/vertex-ai/model-garden)

Very stringent payment verification for Google Cloud.

<table><thead><tr><th>Model Name</th><th>Model Limits</th></tr></thead><tbody>
<tr><td><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental" target="_blank">Gemini 2.5 Pro (Experimental)</a></td><td rowspan="4">10 requests/minute<br>Shared Quota</td></tr>
<tr><td><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental" target="_blank">Gemini 2.0 Flash (Experimental)</a></td></tr>
<tr><td><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental" target="_blank">Gemini 2.0 Flash Thinking (Experimental)</a></td></tr>
<tr><td><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental" target="_blank">Gemini 2.0 Pro (Experimental)</a></td></tr>
<tr><td><a href="https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-4-maverick-17b-128e-instruct-maas" target="_blank">Llama 4 Maverick Instruct</a></td><td>60 requests/minute<br>Free during preview</td></tr>
<tr><td><a href="https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-4-maverick-17b-128e-instruct-maas" target="_blank">Llama 4 Scout Instruct</a></td><td>60 requests/minute<br>Free during preview</td></tr>
<tr><td><a href="https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-3-70b-instruct-maas" target="_blank">Llama 3.3 70B Instruct</a></td><td>30 requests/minute<br>Free during preview</td></tr>
<tr><td><a href="https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-2-90b-vision-instruct-maas" target="_blank">Llama 3.2 90B Vision Instruct</a></td><td>30 requests/minute<br>Free during preview</td></tr>
<tr><td><a href="https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-1-405b-instruct-maas" target="_blank">Llama 3.1 70B Instruct</a></td><td>60 requests/minute<br>Free during preview</td></tr>
<tr><td><a href="https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3-1-405b-instruct-maas" target="_blank">Llama 3.1 8B Instruct</a></td><td>60 requests/minute<br>Free during preview</td></tr>
</tbody></table>



## Providers with trial credits

### [Together](https://together.ai)

**Credits:** $1 when you add a payment method

**Models:** [Various open models](https://together.ai/models)

### [Fireworks](https://fireworks.ai/)

**Credits:** $1

**Models:** [Various open models](https://fireworks.ai/models)

### [Unify](https://unify.ai/)

**Credits:** $5 when you add a payment method

**Models:** Routes to other providers, various open models and proprietary models (OpenAI, Gemini, Anthropic, Mistral, Perplexity, etc)

### [Baseten](https://app.baseten.co/)

**Credits:** $30

**Models:** [Any supported model - pay by compute time](https://www.baseten.co/library/)

### [Nebius](https://studio.nebius.com/)

**Credits:** $1

**Models:** [Various open models](https://studio.nebius.ai/models)

### [Novita](https://novita.ai/referral?invited_code=E5R0CA&ref=ytblmjc&utm_source=affiliate)

**Credits:** $0.5 for 1 year, $20 for 3 months for DeepSeek models with [referral code](https://novita.ai/referral?invited_code=E5R0CA&ref=ytblmjc&utm_source=affiliate) + GitHub account connection

**Models:** [Various open models](https://novita.ai/models)

### [AI21](https://studio.ai21.com/)

**Credits:** $10 for 3 months

**Models:** Jamba family of models

### [Upstage](https://console.upstage.ai/)

**Credits:** $10 for 3 months

**Models:** Solar Pro/Mini

### [NLP Cloud](https://nlpcloud.com/home)

**Credits:** $15

**Requirements:** Phone number verification

**Models:** Various open models

### [Alibaba Cloud (International) Model Studio](https://bailian.console.alibabacloud.com/)

**Credits:** Token/time-limited trials on a per-model basis

**Models:** [Various open and proprietary Qwen models](https://www.alibabacloud.com/en/product/modelstudio)

### [Modal](https://modal.com)

**Credits:** $5/month upon sign up, $30/month with payment method added

**Models:** Any supported model - pay by compute time

### [Hyperbolic](https://app.hyperbolic.xyz/)

**Credits:** $1

**Models:**
- DeepSeek V3
- DeepSeek V3 0324
- Hermes 3 Llama 3.1 70B
- Llama 3 70B Instruct
- Llama 3.1 405B Base
- Llama 3.1 405B Base (FP8)
- Llama 3.1 405B Instruct
- Llama 3.1 70B Instruct
- Llama 3.1 8B Instruct
- Llama 3.2 3B Instruct
- Llama 3.3 70B Instruct
- Pixtral 12B (2409)
- Qwen QwQ 32B
- Qwen QwQ 32B Preview
- Qwen2.5 72B Instruct
- Qwen2.5 Coder 32B Instruct
- Qwen2.5 VL 72B Instruct
- Qwen2.5 VL 7B Instruct

### [SambaNova Cloud](https://cloud.sambanova.ai/)

**Credits:** $5 for 3 months

**Models:**
- E5-Mistral-7B-Instruct
- Llama 3.1 405B
- Llama 3.1 8B
- Llama 3.2 1B
- Llama 3.2 3B
- Llama 3.3 70B
- Llama-4-Maverick-17B-128E-Instruct
- Llama-4-Scout-17B-16E-Instruct
- Llama-Guard-3-8B
- Qwen/QwQ-32B
- Qwen/Qwen2-Audio-7B-Instruct
- deepseek-ai/DeepSeek-R1
- deepseek-ai/DeepSeek-R1-Distill-Llama-70B
- deepseek-ai/DeepSeek-V3-0324

### [Scaleway Generative APIs](https://console.scaleway.com/generative-api/models)

**Credits:** 1,000,000 free tokens

**Models:**
- BGE-Multilingual-Gemma2
- DeepSeek R1 Distill Llama 70B
- DeepSeek R1 Distill Llama 8B
- Gemma 3 27B Instruct
- Llama 3.1 70B Instruct
- Llama 3.1 8B Instruct
- Llama 3.3 70B Instruct
- Mistral Nemo 2407
- Mistral Small 3.1 24B Instruct 2503
- Pixtral 12B (2409)
- Qwen2.5 Coder 32B Instruct
- sentence-t5-xxl


